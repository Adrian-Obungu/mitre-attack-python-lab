# -*- coding: utf-8 -*-
"""
log_parser.py: Log Parser and Analytics for DNS Honeypot Logs

This script parses the log files generated by HoneyResolver_Enhanced.py,
extracts query statistics, and provides threat scoring based on observed
DNS query patterns.

Features:
- Parses honeyresolver.log for DNS query data.
- Provides analytics: total queries, queries per source IP, top queried domains.
- Threat scoring based on query patterns (e.g., queries for fake subdomains, high query volume).
"""

import argparse
import re
from collections import defaultdict, Counter
import json
import os
from typing import Dict, List, Any
import logging
import sys
import time

# --- Configuration ---
DEFAULT_LOG_FILE = "logs/honeyresolver.log" # Assumes log file is in the 'logs' directory

def load_threat_scores():
    """Loads threat scores from an external JSON file."""
    try:
        config_path = os.environ.get("THREAT_SCORES_CONFIG", os.path.join(os.path.dirname(__file__), '..', '..', 'config', 'threat_scores.json'))
        with open(config_path, 'r') as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError) as e:
        logging.critical("Error loading threat scores configuration.", extra={'error': str(e)})
        return {}

THREAT_SCORES = load_threat_scores()

# --- Structured JSON Logging ---
class JsonFormatter(logging.Formatter):
    def format(self, record):
        log_record = {
            "timestamp": self.formatTime(record, self.datefmt),
            "level": record.levelname,
            "message": record.getMessage(),
            "logger": record.name,
            "process_id": record.process,
            "thread_id": record.thread,
            "filename": record.filename,
            "lineno": record.lineno,
        }
        # Add custom fields if they exist
        if hasattr(record, 'client_ip'):
            log_record['client_ip'] = record.client_ip
        if hasattr(record, 'qname'):
            log_record['qname'] = record.qname
        if hasattr(record, 'qtype'):
            log_record['qtype'] = record.qtype
        if hasattr(record, 'resolved_path'):
            log_record['resolved_path'] = record.resolved_path
        if hasattr(record, 'allowed_directory'):
            log_record['allowed_directory'] = record.allowed_directory
            
        # Add any extra dictionary values passed
        if isinstance(record.msg, dict):
            log_record.update(record.msg)
            log_record["message"] = record.msg.get("message", record.getMessage())

        return json.dumps(log_record)

# Setup basic logging for the parser itself
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# Clear existing handlers
if logger.hasHandlers():
    logger.handlers.clear()

# Add a StreamHandler with JSON formatter
console_handler = logging.StreamHandler(sys.stdout)
console_handler.setFormatter(JsonFormatter())
logger.addHandler(console_handler)

class LogParser:
    """
    Parses DNS honeypot logs, extracts statistics, and calculates threat scores.
    """
    def __init__(self, log_file_path: str, threat_scores: Dict):
        """
        Initializes the LogParser with the path to the log file and threat scores.
        """
        self.log_file_path = log_file_path
        self.threat_scores = threat_scores
        self.parsed_entries: List[Dict[str, Any]] = []
        self.query_stats = defaultdict(lambda: defaultdict(int)) # {client_ip: {qtype: count, qname: count, score: int}}
        self.total_queries = 0
        self.top_queried_domains = Counter()

    def _get_threat_score(self, key: str, default: int = 0) -> int:
        """Safely retrieves a threat score from the configuration."""
        return self.threat_scores.get(key, default)

    def parse_logs(self):
        """
        Reads and parses each line of the log file.
        """
        if not os.path.exists(self.log_file_path):
            logger.error(f"Log file not found: {self.log_file_path}")
            return

        logger.info(f"Parsing log file: {self.log_file_path}")
        with open(self.log_file_path, 'r', encoding='utf-8') as f:
            for line in f:
                self._parse_log_line(line)
        logger.info(f"Finished parsing. Total entries: {len(self.parsed_entries)}")

    def _parse_log_line(self, line: str):
        """
        Parses a single log line and extracts relevant information.
        This version uses a specific regex to avoid ReDoS vulnerabilities.
        """
        # This regex is tailored to the log format from HoneyResolver_Enhanced.py
        # Format: Query from {client_ip}: '{sanitized_qname}' (Type: {qtype}) -> {response_ip} ({category})
        log_pattern = re.compile(
            r"Query from\s+([^:]+):\s+'([^']*)'\s+\(Type:\s+(\w+)\)\s+->\s+[^\s]+\s+\((real|fake|random)\)"
        )
        match = log_pattern.search(line)

        if match:
            client_ip = match.group(1)
            qname = match.group(2).lower().strip('.')
            qtype = match.group(3)
            category = match.group(4)

            entry = {
                "client_ip": client_ip,
                "qname": qname,
                "qtype": qtype,
                # A honeypot hit is now determined by the 'category' in the log
                "is_honeypot_hit": category in ['fake', 'random']
            }
            self.parsed_entries.append(entry)
            self._update_statistics(entry)


    def _update_statistics(self, entry: Dict[str, Any]):
        """Updates internal statistics based on a parsed log entry."""
        self.total_queries += 1
        client_ip = entry["client_ip"]
        qname = entry["qname"]
        qtype = entry["qtype"]

        stats = self.query_stats[client_ip]
        stats["total_queries"] += 1
        stats[f"qtype_{qtype}"] += 1
        if "queried_domains" not in stats:
            stats["queried_domains"] = []
        stats["queried_domains"].append(qname)
        self.top_queried_domains[qname] += 1
        
        if "threat_score" not in stats:
            stats["threat_score"] = 0

        # Apply threat scoring using the helper method for safety
        if entry["is_honeypot_hit"]:
            stats["threat_score"] += self._get_threat_score("fake_subdomain_query")
            stats["honeypot_hits"] += 1
            if "admin" in qname:
                stats["threat_score"] += self._get_threat_score("admin_query")
            if "vpn" in qname:
                stats["threat_score"] += self._get_threat_score("vpn_query")
            if "internal" in qname:
                stats["threat_score"] += self._get_threat_score("internal_query")
            if "db" in qname or "sql" in qname:
                stats["threat_score"] += self._get_threat_score("db_query")
            if "secret" in qname or "private" in qname:
                stats["threat_score"] += self._get_threat_score("secret_query")
            if "backup" in qname:
                stats["threat_score"] += self._get_threat_score("backup_query")
            if "remote" in qname:
                stats["threat_score"] += self._get_threat_score("remote_query")
            
            if entry.get("is_dynamic"):
                stats["threat_score"] += (self._get_threat_score("fake_subdomain_query") // 2)

        if stats["total_queries"] > self._get_threat_score("high_query_volume_threshold", 100):
            stats["threat_score"] += self._get_threat_score("high_query_volume_score")
            stats["high_volume_flag"] = True
        
        if qtype == "ANY":
             stats["threat_score"] += self._get_threat_score("suspicious_qtype_query")

    def generate_report(self):
        """Generates and logs a comprehensive analytics report in JSON format."""
        logger.info("Generating analysis report...")
        
        # Log report header as JSON
        report_header = {
            "message": "HONEYRESOLVER LOG ANALYSIS REPORT",
            "log_file": self.log_file_path,
            "analysis_date": time.ctime(),
            "total_dns_queries_processed": self.total_queries
        }
        logger.info(report_header)

        # Log top 10 queried domains as JSON
        if self.top_queried_domains:
            top_domains = [{"qname": qname, "count": count} for qname, count in self.top_queried_domains.most_common(10)]
            logger.info("Top 10 Queried Domains", extra={"top_domains": top_domains})
        
        # Log client IP analysis as JSON
        sorted_clients = sorted(
            self.query_stats.items(),
            key=lambda item: item[1].get("threat_score", 0),
            reverse=True
        )

        for client_ip, stats in sorted_clients:
            score = stats.get("threat_score", 0)
            status = "Suspicious" if score > 0 else "Normal"
            if stats.get("high_volume_flag"):
                status += ", High Volume"

            client_report = {
                "message": "Client IP Analysis",
                "client_ip": client_ip,
                "threat_score": score,
                "status": status,
                "total_queries": stats['total_queries'],
            }
            if stats.get("honeypot_hits"):
                client_report["honeypot_hits"] = stats['honeypot_hits']
            
            query_types = {qtype.replace('qtype_', ''): count for qtype, count in stats.items() if qtype.startswith("qtype_")}
            if query_types:
                client_report["query_types"] = query_types
            
            if score > 0 and stats.get("queried_domains"):
                client_report["unique_queried_domains"] = sorted(list(set(stats["queried_domains"])))
            
            logger.info(client_report)

def validate_log_file_path(log_file_path: str) -> Optional[str]:
    """
    Validates the log file path to prevent directory traversal and ensure it exists.
    A safe path is one that resolves to a file within the project's 'logs' directory.
    """
    # Get the absolute path of the project root
    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
    logs_dir = os.path.join(project_root, 'logs')
    
    # Resolve the absolute path of the user-provided path
    user_path = os.path.abspath(os.path.join(logs_dir, log_file_path))

    # Security Check: Ensure the resolved path is within the logs directory
    if not user_path.startswith(logs_dir):
        logger.warning("Path traversal attempt blocked.", extra={
            'attempted_path': log_file_path,
            'resolved_path': user_path,
            'allowed_directory': logs_dir
        })
        return None
        
    if os.path.exists(user_path) and os.path.isfile(user_path):
        return user_path
        
    return None

def main():
    """Main function to parse arguments and run the log analysis."""
    parser = argparse.ArgumentParser(
        description="Parse HoneyResolver logs and generate analytics with threat scoring."
    )
    parser.add_argument(
        "log_file",
        nargs="?",
        default=DEFAULT_LOG_FILE,
        help=f"Path to the HoneyResolver log file (default: {DEFAULT_LOG_FILE}). Must be inside the 'logs' directory."
    )
    args = parser.parse_args()

    # --- Input Validation ---
    validated_path = validate_log_file_path(args.log_file)
    if not validated_path:
        logger.critical("Invalid or unsafe log file path specified.", extra={'log_file': args.log_file})
        sys.exit(f"Error: The log file must be a valid file located within the 'logs' directory.")

    # Pass the loaded threat scores to the parser instance
    log_parser = LogParser(validated_path, THREAT_SCORES)
    log_parser.parse_logs()
    
    # Generate report will now log JSON output
    log_parser.generate_report()

if __name__ == "__main__":
    main()
